// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package provider

import (
	"context"
	"fmt"
	"github.com/aballiet/terraform-provider-airbyte/internal/sdk"
	"github.com/aballiet/terraform-provider-airbyte/internal/sdk/pkg/models/shared"

	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
)

// Ensure provider defined types fully satisfy framework interfaces.
var _ datasource.DataSource = &ConnectionDataSource{}
var _ datasource.DataSourceWithConfigure = &ConnectionDataSource{}

func NewConnectionDataSource() datasource.DataSource {
	return &ConnectionDataSource{}
}

// ConnectionDataSource is the data source implementation.
type ConnectionDataSource struct {
	client *sdk.SDK
}

// ConnectionDataSourceModel describes the data model.
type ConnectionDataSourceModel struct {
	BreakingChange               types.Bool              `tfsdk:"breaking_change"`
	ConnectionID                 types.String            `tfsdk:"connection_id"`
	DestinationID                types.String            `tfsdk:"destination_id"`
	Geography                    types.String            `tfsdk:"geography"`
	Name                         types.String            `tfsdk:"name"`
	NamespaceDefinition          types.String            `tfsdk:"namespace_definition"`
	NamespaceFormat              types.String            `tfsdk:"namespace_format"`
	NonBreakingChangesPreference types.String            `tfsdk:"non_breaking_changes_preference"`
	NotifySchemaChanges          types.Bool              `tfsdk:"notify_schema_changes"`
	NotifySchemaChangesByEmail   types.Bool              `tfsdk:"notify_schema_changes_by_email"`
	OperationIds                 []types.String          `tfsdk:"operation_ids"`
	Prefix                       types.String            `tfsdk:"prefix"`
	ResourceRequirements         *ResourceRequirements   `tfsdk:"resource_requirements"`
	ScheduleData                 *ConnectionScheduleData `tfsdk:"schedule_data"`
	ScheduleType                 types.String            `tfsdk:"schedule_type"`
	SourceCatalogID              types.String            `tfsdk:"source_catalog_id"`
	SourceID                     types.String            `tfsdk:"source_id"`
	Status                       types.String            `tfsdk:"status"`
	SyncCatalog                  AirbyteCatalog          `tfsdk:"sync_catalog"`
	WorkspaceID                  types.String            `tfsdk:"workspace_id"`
}

// Metadata returns the data source type name.
func (r *ConnectionDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_connection"
}

// Schema defines the schema for the data source.
func (r *ConnectionDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "Connection DataSource",

		Attributes: map[string]schema.Attribute{
			"breaking_change": schema.BoolAttribute{
				Computed: true,
			},
			"connection_id": schema.StringAttribute{
				Required: true,
			},
			"destination_id": schema.StringAttribute{
				Computed: true,
			},
			"geography": schema.StringAttribute{
				Computed:    true,
				Description: `must be one of ["auto", "us", "eu"]`,
			},
			"name": schema.StringAttribute{
				Computed: true,
			},
			"namespace_definition": schema.StringAttribute{
				Computed: true,
				MarkdownDescription: `must be one of ["source", "destination", "customformat"]` + "\n" +
					`Method used for computing final namespace in destination`,
			},
			"namespace_format": schema.StringAttribute{
				Computed: true,
				MarkdownDescription: `Default: null` + "\n" +
					`Used when namespaceDefinition is 'customformat'. If blank then behaves like namespaceDefinition = 'destination'. If "${SOURCE_NAMESPACE}" then behaves like namespaceDefinition = 'source'.`,
			},
			"non_breaking_changes_preference": schema.StringAttribute{
				Computed:    true,
				Description: `must be one of ["ignore", "disable", "propagate_columns", "propagate_fully"]`,
			},
			"notify_schema_changes": schema.BoolAttribute{
				Computed: true,
			},
			"notify_schema_changes_by_email": schema.BoolAttribute{
				Computed: true,
			},
			"operation_ids": schema.ListAttribute{
				Computed:    true,
				ElementType: types.StringType,
			},
			"prefix": schema.StringAttribute{
				Computed:    true,
				Description: `Prefix that will be prepended to the name of each stream when it is written to the destination.`,
			},
			"resource_requirements": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"cpu_request": schema.StringAttribute{
						Computed: true,
					},
					"cpu_limit": schema.StringAttribute{
						Computed: true,
					},
					"memory_request": schema.StringAttribute{
						Computed: true,
					},
					"memory_limit": schema.StringAttribute{
						Computed: true,
					},
				},
				Description: `optional resource requirements to run workers (blank for unbounded allocations)`,
			},
			"schedule_data": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"basic_schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"time_unit": schema.StringAttribute{
								Computed:    true,
								Description: `must be one of ["minutes", "hours", "days", "weeks", "months"]`,
							},
							"units": schema.Int64Attribute{
								Computed: true,
							},
						},
					},
					"cron": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_expression": schema.StringAttribute{
								Computed: true,
							},
							"cron_time_zone": schema.StringAttribute{
								Computed: true,
							},
						},
					},
				},
				Description: `schedule for when the the connection should run, per the schedule type`,
			},
			"schedule_type": schema.StringAttribute{
				Computed: true,
				MarkdownDescription: `must be one of ["manual", "basic", "cron"]` + "\n" +
					`determine how the schedule data should be interpreted`,
			},
			"source_catalog_id": schema.StringAttribute{
				Computed: true,
			},
			"source_id": schema.StringAttribute{
				Computed: true,
			},
			"status": schema.StringAttribute{
				Computed: true,
				MarkdownDescription: `must be one of ["active", "inactive", "deprecated"]` + "\n" +
					`Active means that data is flowing through the connection. Inactive means it is not. Deprecated means the connection is off and cannot be re-activated. the schema field describes the elements of the schema that will be synced.`,
			},
			"sync_catalog": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"streams": schema.ListNestedAttribute{
						Computed: true,
						NestedObject: schema.NestedAttributeObject{
							Attributes: map[string]schema.Attribute{
								"stream": schema.SingleNestedAttribute{
									Computed: true,
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed:    true,
											Description: `Stream's name.`,
										},
										"json_schema": schema.MapAttribute{
											Computed:    true,
											ElementType: types.StringType,
											Description: `Stream schema using Json Schema specs.`,
										},
										"supported_sync_modes": schema.ListAttribute{
											Computed:    true,
											ElementType: types.StringType,
										},
										"source_defined_cursor": schema.BoolAttribute{
											Computed:    true,
											Description: `If the source defines the cursor field, then any other cursor field inputs will be ignored. If it does not, either the user_provided one is used, or the default one is used as a backup.`,
										},
										"default_cursor_field": schema.ListAttribute{
											Computed:    true,
											ElementType: types.StringType,
											Description: `Path to the field that will be used to determine if a record is new or modified since the last sync. If not provided by the source, the end user will have to specify the comparable themselves.`,
										},
										"source_defined_primary_key": schema.ListAttribute{
											Computed: true,
											ElementType: types.ListType{
												ElemType: types.StringType,
											},
											Description: `If the source defines the primary key, paths to the fields that will be used as a primary key. If not provided by the source, the end user will have to specify the primary key themselves.`,
										},
										"namespace": schema.StringAttribute{
											Computed:    true,
											Description: `Optional Source-defined namespace. Airbyte streams from the same sources should have the same namespace. Currently only used by JDBC destinations to determine what schema to write to.`,
										},
									},
									Description: `the immutable schema defined by the source`,
								},
								"config": schema.SingleNestedAttribute{
									Computed: true,
									Attributes: map[string]schema.Attribute{
										"sync_mode": schema.StringAttribute{
											Computed:    true,
											Description: `must be one of ["full_refresh", "incremental"]`,
										},
										"cursor_field": schema.ListAttribute{
											Computed:    true,
											ElementType: types.StringType,
											Description: `Path to the field that will be used to determine if a record is new or modified since the last sync. This field is REQUIRED if ` + "`" + `sync_mode` + "`" + ` is ` + "`" + `incremental` + "`" + `. Otherwise it is ignored.`,
										},
										"destination_sync_mode": schema.StringAttribute{
											Computed:    true,
											Description: `must be one of ["append", "overwrite", "append_dedup"]`,
										},
										"primary_key": schema.ListAttribute{
											Computed: true,
											ElementType: types.ListType{
												ElemType: types.StringType,
											},
											Description: `Paths to the fields that will be used as primary key. This field is REQUIRED if ` + "`" + `destination_sync_mode` + "`" + ` is ` + "`" + `*_dedup` + "`" + `. Otherwise it is ignored.`,
										},
										"alias_name": schema.StringAttribute{
											Computed:    true,
											Description: `Alias name to the stream to be used in the destination`,
										},
										"selected": schema.BoolAttribute{
											Computed:    true,
											Description: `If this is true, the stream is selected with all of its properties. For new connections, this considers if the stream is suggested or not`,
										},
										"suggested": schema.BoolAttribute{
											Computed:    true,
											Description: `Does the connector suggest that this stream be enabled by default?`,
										},
										"field_selection_enabled": schema.BoolAttribute{
											Computed:    true,
											Description: `Whether field selection should be enabled. If this is true, only the properties in ` + "`" + `selectedFields` + "`" + ` will be included.`,
										},
										"selected_fields": schema.ListNestedAttribute{
											Computed: true,
											NestedObject: schema.NestedAttributeObject{
												Attributes: map[string]schema.Attribute{
													"field_path": schema.ListAttribute{
														Computed:    true,
														ElementType: types.StringType,
													},
												},
											},
											Description: `Paths to the fields that will be included in the configured catalog. This must be set if ` + "`" + `fieldSelectedEnabled` + "`" + ` is set. An empty list indicates that no properties will be included.`,
										},
									},
									Description: `the mutable part of the stream to configure the destination`,
								},
							},
						},
					},
				},
				Description: `describes the available schema (catalog).`,
			},
			"workspace_id": schema.StringAttribute{
				Computed: true,
			},
		},
	}
}

func (r *ConnectionDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*sdk.SDK)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected DataSource Configure Type",
			fmt.Sprintf("Expected *sdk.SDK, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

func (r *ConnectionDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data *ConnectionDataSourceModel
	var item types.Object

	resp.Diagnostics.Append(req.Config.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	connectionID := data.ConnectionID.ValueString()
	request := shared.ConnectionIDRequestBody{
		ConnectionID: connectionID,
	}
	res, err := r.client.Connection.GetConnection(ctx, request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if res.ConnectionRead == nil {
		resp.Diagnostics.AddError("unexpected response from API. No response body", debugResponse(res.RawResponse))
		return
	}
	data.RefreshFromGetResponse(res.ConnectionRead)

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
